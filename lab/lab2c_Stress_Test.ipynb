{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../imgs/MLU_Logo.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Stress Test\n",
    "\n",
    "The idea of this notebook is to see how the [production endpoint](https://console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints/iris-model-production) will behave when a **bunch** of requests arrive it.\n",
    "\n",
    "\n",
    "We will simulate hundreds of users to do the predictions at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import boto3\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "endpoint_name_mask='iris-model-%s'\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "def predict(payload):\n",
    "    csv_serializer = CSVSerializer()\n",
    "    payload = payload\n",
    "    X = payload[1:]\n",
    "    y = payload[0]\n",
    "    \n",
    "    elapsed_time = time.time()\n",
    "    resp = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_mask % env,\n",
    "        ContentType='text/csv',\n",
    "        Accept='text/csv',\n",
    "        Body=csv_serializer.serialize(X)\n",
    "    )\n",
    "    elapsed_time = time.time() - elapsed_time\n",
    "    resp = float(resp['Body'].read().decode('utf-8').strip())\n",
    "    return (resp == y, elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(max_threads, max_requests):\n",
    "    num_batches = math.ceil(max_requests / len(dataset))\n",
    "    requests = []\n",
    "    for i in range(num_batches):\n",
    "        batch = dataset.copy()\n",
    "        np.random.shuffle(batch)\n",
    "        requests += batch.tolist()\n",
    "    len(requests)\n",
    "\n",
    "    pool = ThreadPool(max_threads)\n",
    "    result = pool.map(predict, requests)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    correct_random_forest=0\n",
    "    elapsedtime_random_forest=0\n",
    "    for i in result:\n",
    "        correct_random_forest += i[0]\n",
    "        elapsedtime_random_forest += i[1]\n",
    "    print(\"Score classifier: {}\".format(correct_random_forest/len(result)))\n",
    "\n",
    "    print(\"Elapsed time: {}s\".format(elapsedtime_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env='production'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: 1000 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test 1\n",
      "Score classifier: 0.96\n",
      "Elapsed time: 18.000831127166748s\n",
      "CPU times: user 2.33 s, sys: 161 ms, total: 2.49 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Starting test 1\")\n",
    "run_test(10, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: 10,000 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test 2\n",
      "Score classifier: 0.96\n",
      "Elapsed time: 2403.5203816890717s\n",
      "CPU times: user 30.9 s, sys: 2.13 s, total: 33 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Starting test 2\")\n",
    "run_test(100, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: 100,000 requests\n",
    "\n",
    "Note this test may take around **5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test 3\n",
      "Score classifier: 0.96\n",
      "Elapsed time: 35163.71126294136s\n",
      "CPU times: user 6min 43s, sys: 38.7 s, total: 7min 22s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Starting test 3\")\n",
    "run_test(150, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudwatch Monitoring\n",
    "\n",
    "> **Action**: While this test is running, go to the [**Sagemaker Endpoints**](https://console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints/iris-model-production), then click on\n",
    "the `View invocation metrics` to see the endpoint behavior on CloudWatch.\n",
    "\n",
    "<img src=\"../imgs/sagemaker_endpoints.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CloudWatch, check the following three checkboxes:\n",
    "\n",
    "<img src=\"../imgs/all_metrics.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "Then, change the config (marked in RED) as following:\n",
    "\n",
    "\n",
    "<img src=\"../imgs/invocation_point.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Scaling Alarm\n",
    "\n",
    "Now, while your stress test 3 is still running, you will see the **Auto Scaling Alarm** like this, after 3 datapoints above 750 Invocations Per Instance\n",
    "\n",
    "<img src=\"../imgs/alarm.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "When this happens, the endpoint **autoscaling** will start adding more instances to your cluster. You can observe in the Graph from the previous image that, after new instances are added to the cluster, the invocations metrics grows.\n",
    "\n",
    "<img src=\"../imgs/autoscaling.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Resources:\n",
    "\n",
    "For more information about CloudWatch metrics, check the [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html) for more details!\n",
    "\n",
    "---\n",
    "![logo](../imgs/MLU_Logo.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
